<!DOCTYPE html>
<html lang="en">
<head>
  <title>Publications</title>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/>
  <link href="https://fonts.googleapis.com/css?family=Poppins:300,400,500,600,700" rel="stylesheet"/>
  <link href="https://fonts.googleapis.com/css?family=Montserrat:300,400,500,700" rel="stylesheet"/>
  <link href="https://fonts.googleapis.com/css?family=Herr+Von+Muellerhoff" rel="stylesheet"/>
  <link rel="stylesheet" href="css/open-iconic-bootstrap.min.css"/>
  <link rel="stylesheet" href="css/animate.css"/>
  <link rel="stylesheet" href="css/owl.carousel.min.css"/>
  <link rel="stylesheet" href="css/owl.theme.default.min.css"/>
  <link rel="stylesheet" href="css/magnific-popup.css"/>
  <link rel="stylesheet" href="css/aos.css"/>
  <link rel="stylesheet" href="css/ionicons.min.css"/>
  <link rel="stylesheet" href="css/bootstrap-datepicker.css"/>
  <link rel="stylesheet" href="css/jquery.timepicker.css"/>
  <link rel="stylesheet" href="css/flaticon.css"/>
  <link rel="stylesheet" href="css/icomoon.css"/>
  <link rel="stylesheet" href="css/style.css"/>
</head>
<body>
<div id="colorlib-page">
  <a href="#" class="js-colorlib-nav-toggle colorlib-nav-toggle"><i></i></a>
  <aside id="colorlib-aside" role="complementary" class="js-fullheight text-center">
    <h1 id="colorlib-logo"><a href="index.html" style="color: #f4a460"><span class="img" style="background-image: url(images/author.jpg)"></span>Chahat Raj</a></h1>
    <nav id="colorlib-main-menu" role="navigation">
      <ul>
        <li class="colorlib-active"><a href="./files/chahat_cv.pdf" style="color: #f4a460">CV</a></li>
        <li class="colorlib-active"><a href="news.html" style="color: #f4a460">News</a></li>
        <li class="colorlib-active"><a href="affiliations.html" style="color: #f4a460">Affiliations</a></li>
        <li class="colorlib-active"><a href="publications.html" style="color: #f4a460">Publications</a></li>
        <li class="colorlib-active"><a href="services.html" style="color: #f4a460">Services</a></li>
        <li class="colorlib-active"><a href="contact.html" style="color: #f4a460">Contact</a></li>
        <ul class="ftco-social mt-3">
          <li class="ftco-animate"><a href="https://linkedin.com/in/chahatraj" style="color: #f4a460"><span class="icon-linkedin"></span></a></li>
          <li class="ftco-animate"><a href="https://facebook.com/chahat.raj.71" style="color: #f4a460"><span class="icon-facebook"></span></a></li>
          <li class="ftco-animate"><a href="https://instagram.com/chatty_chahat" style="color: #f4a460"><span class="icon-instagram"></span></a></li>
          <li class="ftco-animate"><a href="https://twitter.com/chahat__raj" style="color: #f4a460"><span class="icon-twitter"></span></a></li>
        </ul>
      </ul>
    </nav>
  </aside>
  <div id="colorlib-main">
    <div class="author-info text p-3 p-md-5">
      <section class="desc">
        <div class="container">
          <div class="row d-flex">
            <div class="col-lg-32">
              <div class="row">
                <div class="col-md-12">
                  <h1 class="mb-4" style="color: #f4a460"><span></span><b>PUBLICATIONS</b><span></span></h1>
                  <p align="center">
                    <a href="https://scholar.google.com/citations?user=K8EKC4gAAAAJ&hl=en&oi=ao" target="_blank" class="btn-round btn-primary btn" style="background-color: #f4a460">Google Scholar</a>
                  </p>
                  <br/>
                  <ul>
                    <h1 class="mb-4" style="color: #f4a460" align="left">
                      <span></span><b>Doctoral Research</b><span></span>
                    </h1>
                    <!-- Publication 5 Starts Here -->
                    <li>
                      <p>
                        <a style="color: #000000">BiasDora: Exploring Hidden Biased Associations in Vision-Language Models.</a><br />
                        <a style="color: #f4a460">Chahat Raj</a>, Anjishnu Mukherjee, Aylin Caliskan, Antonios Anastasopoulos, and Ziwei Zhu (Under Review 2024)
                        <button type="button" class="btn badge" style="background-color: #a7c7e7; color: #ffffff" data-popup="absd5">Abstract</button>
                        <a href="./files/d5.pdf""><button type="button" class="btn badge" style="background-color: #ec949c; color: #ffffff">PDF</button></a> <!-- TODO: add pdf -->
                        <a href=""><button type="button" class="btn badge" style="background-color: #ebce77; color: #ffffff">Code</button></a> <!-- TODO: add code -->
                        <button type="button" class="btn badge" style="background-color: #b8d8be; color: #ffffff" data-popup="bibd5">BibTeX</button>
                      </p>
                      <div id="absd5" class="popup-abs" style="display: none; font-size: 12px; text-align: justify;">
                        Existing works examining Vision Language Models (VLMs) for social biases predominantly focus on a limited set of documented bias associations, 
                        such as gender-profession or race-crime. This narrow scope often overlooks a vast range of unexamined implicit associations, 
                        restricting the identification and, hence, mitigation of such biases. We address this gap by probing VLMs to (1) uncover hidden, implicit associations across 
                        9 bias dimensions. We systematically explore diverse input and output modalities and (2) demonstrate how biased associations vary in their negativity, toxicity, 
                        and extremity. Our work (3) identifies subtle and extreme biases that are typically not recognized by existing methodologies. We make the Dataset of retrieved 
                        associations, (Dora), publicly available. <br /> <br />
                      </div>
                      <div id="bibd5" class="popup-bib" style="display: none; font-size: 12px; text-align: left; white-space: pre; padding-top: -20px !important">
                        @article{raj2024biasdora,
                          title={BiasDora: Exploring Hidden Biased Associations in Vision-Language Models.},
                          author={Raj, Chahat and Mukherjee, Anjishnu and Caliskan, Aylin and Anastasopoulos, Antonios and Zhu, Ziwei},
                          journal={},
                          year={2024}
                        }
                      </div>                                            
                    </li>
                    <!-- Publication 5 Ends Here -->
                    <!-- Publication 4 Starts Here -->
                    <li>
                      <p>
                        <a style="color: #000000">Breaking Bias, Building Bridges: Evaluation and Mitigation of Social Biases in LLMs via Contact Hypothesis.</a><br />
                        <a style="color: #f4a460">Chahat Raj</a>, Anjishnu Mukherjee, Aylin Caliskan, Antonios Anastasopoulos, and Ziwei Zhu (Under Review 2024)
                        <button type="button" class="btn badge" style="background-color: #a7c7e7; color: #ffffff" data-popup="absd4">Abstract</button>
                        <a href="./files/d4.pdf""><button type="button" class="btn badge" style="background-color: #ec949c; color: #ffffff">PDF</button></a> <!-- TODO: add pdf -->
                        <a href=""><button type="button" class="btn badge" style="background-color: #ebce77; color: #ffffff">Code</button></a> <!-- TODO: add code -->
                        <button type="button" class="btn badge" style="background-color: #b8d8be; color: #ffffff" data-popup="bibd4">BibTeX</button>
                      </p>
                      <div id="absd4" class="popup-abs" style="display: none; font-size: 12px; text-align: justify;">
                        Large Language Models (LLMs) perpetuate social biases, reflecting prejudices in their training data and reinforcing societal stereotypes
                        and inequalities. Our work explores the potential of the Contact Hypothesis, a concept from social psychology for debiasing LLMs. We simulate 
                        various forms of social contact through LLM prompting to measure their influence on the model's biases, mirroring how intergroup interactions 
                        can reduce prejudices in social contexts. We create a dataset of 108,000 prompts following a principled approach replicating social contact to 
                        measure biases in three LLMs (LLaMA 2, Tulu, and NousHermes) across 13 social bias dimensions. We propose a unique debiasing technique, 
                        Social Contact Debiasing (SCD), that instruction-tunes these models with unbiased responses to prompts. Our research demonstrates that LLM 
                        responses exhibit social biases when subject to contact probing, but more importantly, these biases can be significantly reduced by up to 40% 
                        in 1 epoch of instruction tuning LLaMA 2 following our SCD strategy. <br /> <br />
                      </div>
                      <div id="bibd4" class="popup-bib" style="display: none; font-size: 12px; text-align: left; white-space: pre; padding-top: -20px !important">
                        @article{raj2024breakingbias,
                          title={Breaking Bias, Building Bridges: Evaluation and Mitigation of Social Biases in LLMs via Contact Hypothesis.},
                          author={Raj, Chahat and Mukherjee, Anjishnu and Caliskan, Aylin and Anastasopoulos, Antonios and Zhu, Ziwei},
                          journal={},
                          year={2024}
                        }
                      </div>                                            
                    </li>
                    <!-- Publication 4 Ends Here -->
                    <!-- Publication 3 Starts Here -->
                    <li>
                      <p>
                        <a style="color: #000000">SALSA: Salience-Based Switching Attack for Adversarial Perturbations in Fake News Detection Models.</a><br />
                        <a style="color: #f4a460">Chahat Raj*</a>, Anjishnu Mukherjee*, Hemant Purohit, Antonios Anastasopoulos, and Ziwei Zhu (ECIR 2024)
                        <button type="button" class="btn badge" style="background-color: #a7c7e7; color: #ffffff" data-popup="absd3">Abstract</button>
                        <a href="./files/d3.pdf"><button type="button" class="btn badge" style="background-color: #ec949c; color: #ffffff">PDF</button></a>
                        <a href="https://github.com/iamshnoo/salsa"><button type="button" class="btn badge" style="background-color: #ebce77; color: #ffffff">Code</button></a>
                        <button type="button" class="btn badge" style="background-color: #b8d8be; color: #ffffff" data-popup="bibd3">BibTeX</button>
                      </p>
                      <div id="absd3" class="popup-abs" style="display: none; font-size: 12px; text-align: justify;">
                        Despite advances in fake news detection algorithms, recent research reveals that machine learning-based fake news detection models are still 
                        vulnerable to carefully crafted adversarial attacks. In this landscape, traditional methods, often relying on text perturbations or
                        heuristic-based approaches, have proven insufficient, revealing a critical need for more nuanced and context-aware strategies to enhance the 
                        robustness of fake news detection. Our research identifies and addresses three critical areas: creating subtle perturbations, preserving core 
                        information while modifying sentence structure, and incorporating inherent interpretability. We propose SALSA, an adversarial Salience-based
                        Switching Attack strategy that harnesses salient words, using similaritybased switching to address the shortcomings of traditional adversarial
                        attack methods. Using SALSA, we perform a two-way attack: misclassifying real news as fake and fake news as real. Due to the absence of
                        standardized metrics to evaluate adversarial attacks in fake news detection, we further propose three new evaluation metrics to gauge the attack's 
                        success. Finally, we validate the transferability of our proposed attack strategy across attacker and victim models, demonstrating our
                        approach's broad applicability and potency. <br /> <br />
                      </div>
                      <div id="bibd3" class="popup-bib" style="display: none; font-size: 12px; text-align: left; white-space: pre; padding-top: -20px !important">
                        @inproceedings{raj2024salsa,
                          title={SALSA: Salience-Based Switching Attack for Adversarial Perturbations in Fake News Detection Models},
                          author={Raj, Chahat and Mukherjee, Anjishnu and Purohit, Hemant and Anastasopoulos, Antonios and Zhu, Ziwei},
                          booktitle={European Conference on Information Retrieval},
                          pages={35--49},
                          year={2024},
                          organization={Springer}
                        }
                      </div>                                            
                    </li>
                    <!-- Publication 3 Ends Here -->
                    <!-- Publication 2 Starts Here -->
                    <li>
                      <p>
                        <a style="color: #000000">Global Voices, Local Biases: Socio-Cultural Prejudices across Languages.</a><br />
                        Anjishnu Mukherjee*, <a style="color: #f4a460">Chahat Raj*</a>, Ziwei Zhu, and Antonios Anastasopoulos (EMNLP 2023)
                        <button type="button" class="btn badge" style="background-color: #a7c7e7; color: #ffffff" data-popup="absd2">Abstract</button>
                        <a href="./files/d2.pdf"><button type="button" class="btn badge" style="background-color: #ec949c; color: #ffffff">PDF</button></a>
                        <a href="https://github.com/iamshnoo/weathub"><button type="button" class="btn badge" style="background-color: #ebce77; color: #ffffff">Code</button></a>
                        <button type="button" class="btn badge" style="background-color: #b8d8be; color: #ffffff" data-popup="bibd2">BibTeX</button>
                      </p>
                      <div id="absd2" class="popup-abs" style="display: none; font-size: 12px; text-align: justify;">
                        Human biases are ubiquitous but not uniform: disparities exist across linguistic, cultural, and societal borders. As large amounts of recent 
                        literature suggest, language models (LMs) trained on human data can reflect and often amplify the effects of these social biases. However, 
                        the vast majority of existing studies on bias are heavily skewed towards Western and European languages. In this work, we scale the Word 
                        Embedding Association Test (WEAT) to 24 languages, enabling broader studies and yielding interesting findings about LM bias. We additionally 
                        enhance this data with culturally relevant information for each language, capturing local contexts on a global scale. Further, to encompass 
                        more widely prevalent societal biases, we examine new bias dimensions across toxicity, ableism, and more. Moreover, we delve deeper into the 
                        Indian linguistic landscape, conducting a comprehensive regional bias analysis across six prevalent Indian languages. Finally, we highlight 
                        the significance of these social biases and the new dimensions through an extensive comparison of embedding methods, reinforcing the need to 
                        address them in pursuit of more equitable language models. <br /> <br />
                      </div>
                      <div id="bibd2" class="popup-bib" style="display: none; font-size: 12px; text-align: left; white-space: pre; padding-top: -20px !important">
                        @inproceedings{mukherjee-etal-2023-global,
                          title = "{G}lobal {V}oices, Local Biases: Socio-Cultural Prejudices across Languages",
                          author = "Mukherjee, Anjishnu  and Raj, Chahat  and Zhu, Ziwei  and Anastasopoulos, Antonios",
                          editor = "Bouamor, Houda  and Pino, Juan  and Bali, Kalika",
                          booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
                          month = dec,
                          year = "2023",
                          address = "Singapore",
                          publisher = "Association for Computational Linguistics",
                          url = "https://aclanthology.org/2023.emnlp-main.981",
                          doi = "10.18653/v1/2023.emnlp-main.981",
                          pages = "15828--15845",
                      }
                      </div>                                            
                    </li>
                    <!-- Publication 2 Ends Here -->
                    <!-- Publication 1 Starts Here -->
                    <li>
                      <p>
                        <a style="color: #000000">True and Fair: Robust and Unbiased Fake News Detection via Interpretable Machine Learning.</a><br />
                        <a style="color: #f4a460">Chahat Raj</a>, Anjishnu Mukherjee and Ziwei Zhu (AAAI/ACM AIES 2023)
                        <button type="button" class="btn badge" style="background-color: #a7c7e7; color: #ffffff" data-popup="absd1">Abstract</button>
                        <a href="./files/d1.pdf"><button type="button" class="btn badge" style="background-color: #ec949c; color: #ffffff">PDF</button></a>
                        <a href="https://github.com/chahatraj/true-and-fair"><button type="button" class="btn badge" style="background-color: #ebce77; color: #ffffff">Code</button></a>
                        <button type="button" class="btn badge" style="background-color: #b8d8be; color: #ffffff" data-popup="bibd1">BibTeX</button>
                      </p>
                      <div id="absd1" class="popup-abs" style="display: none; font-size: 12px; text-align: justify;">
                        The dissemination of information, and consequently, misinformation, occurs at an unprecedented speed, making it increasingly difficult to 
                        discern the credibility of rapidly circulating news. Advanced large-scale language models have facilitated the development of classifiers 
                        capable of effectively identifying misinformation. Nevertheless, these models are intrinsically susceptible to biases that may be introduced 
                        through numerous ways, including contaminated data sources or unfair training methodologies. When trained on biased data, machine learning 
                        models may inadvertently learn and reinforce these biases, leading to reduced generalization performance. This situation consequently results 
                        in an inherent "unfairness" within the system. Interpretability, referring to the ability to understand and explain the decision-making 
                        process of a model, can be used as a tool to explain these biases. Our research aims to identify the root causes of these biases in fake news 
                        detection and mitigate their presence using interpretability. We also perform inference time attacks to fairness to validate robustness. <br /> <br />
                      </div>
                      <div id="bibd1" class="popup-bib" style="display: none; font-size: 12px; text-align: left; white-space: pre; padding-top: -20px !important">
                        @inproceedings{10.1145/3600211.3604760,
                          author = {Raj, Chahat and Mukherjee, Anjishnu and Zhu, Ziwei},
                          title = {True and Fair: Robust and Unbiased Fake News Detection via Interpretable Machine Learning},
                          year = {2023},
                          isbn = {9798400702310},
                          publisher = {Association for Computing Machinery},
                          address = {New York, NY, USA},
                          url = {https://doi.org/10.1145/3600211.3604760},
                          doi = {10.1145/3600211.3604760},
                          booktitle = {Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
                          pages = {962-963},
                          numpages = {2},
                          keywords = {security, misinformation, interpretability, fairness, bias},
                          location = {<conf-loc>, <city>Montr\'{e}al</city>, <state>QC</state>, <country>Canada</country>, </conf-loc>},
                          series = {AIES '23}
                          }
                      </div>                                            
                    </li>
                    <!-- Publication 1 Ends Here -->

                    <h1 class="mb-4" style="color: #f4a460" align="left">
                      <span></span><b>Master's Research</b><span></span>
                    </h1>
                    <!-- Publication 15 Starts Here -->
                    <li>
                      <p>
                        <a style="color: #000000">Bitcoin Price Prediction using LSTM Autoencoder and False Nearest Neighbor Loss.</a><br />
                        <a style="color: #f4a460">Chahat Raj</a> and Manojit Chattopadhyay (Under Review 2024)
                        <button type="button" class="btn badge" style="background-color: #a7c7e7; color: #ffffff" data-popup="absm15">Abstract</button>
                        <a href="./files/m15.pdf"><button type="button" class="btn badge" style="background-color: #ec949c; color: #ffffff">PDF</button></a> <!-- TODO: add pdf -->
                        <a href="https://github.com/chahatraj/LSTM-Autoencoder-FNN"><button type="button" class="btn badge" style="background-color: #ebce77; color: #ffffff">Code</button></a> <!-- TODO: add code -->
                        <button type="button" class="btn badge" style="background-color: #b8d8be; color: #ffffff" data-popup="bibm15">BibTeX</button>
                      </p>
                      <div id="absm15" class="popup-abs" style="display: none; font-size: 12px; text-align: justify;">
                        We implement deep learning for predicting bitcoin closing prices. Identifying two new determiners, we propose a novel LSTM Autoencoder 
                        using Mean Squared Error (MSE) loss which is regularized by False Nearest Neighbor (FNN) algorithm. The method results in reduced error 
                        rates when compared to traditional forecasting algorithms and is statistically validated. This research contributes by developing a 
                        robust algorithm that accurately determines the fluctuation directions in bitcoin prices and results in values closer to the actual prices. <br /> <br />
                      </div>
                      <div id="bibm15" class="popup-bib" style="display: none; font-size: 12px; text-align: left; white-space: pre; padding-top: -20px !important">
                        @article{rajbitcoin,
                          title={Bitcoin Price Prediction using LSTM Autoencoder Regularized by False Nearest Neighbor Loss},
                          author={Raj, Chahat and Chattopadhyay, Manojit}
                        } <!-- TODO update bib -->
                      </div>                                            
                    </li>           
                    <!-- Publication 15 ends here -->

                    <!-- Publication 14 Starts Here -->
                    <li>
                      <p>
                        <a style="color: #000000">Machine Learning Models help Differentiate between Causes of Recurrent Spontaneous Vertigo.</a><br />
                        Chao Wang, Allison S Young, <a style="color: #f4a460">Chahat Raj</a>, Andrew P Bradshaw, Benjamin Nham, Sally M Rosengren, Zeljka Calic, David Burke, 
                        G Michael Halmagyi, Gnana K Bharathy, Mukesh Prasad, and Miriam S Welgampola (Journal of Neurology 2024)
                        <button type="button" class="btn badge" style="background-color: #a7c7e7; color: #ffffff" data-popup="absm14">Abstract</button>
                        <a href="./files/m14.pdf"><button type="button" class="btn badge" style="background-color: #ec949c; color: #ffffff">PDF</button></a> <!-- TODO: add pdf -->
                        <a href=""><button type="button" class="btn badge" style="background-color: #ebce77; color: #ffffff">Code</button></a> <!-- TODO: add code -->
                        <button type="button" class="btn badge" style="background-color: #b8d8be; color: #ffffff" data-popup="bibm14">BibTeX</button>
                      </p>
                      <div id="absm14" class="popup-abs" style="display: none; font-size: 12px; text-align: justify;">
                        Vestibular migraine (VM) and Menière's disease (MD) are two common causes of recurrent spontaneous vertigo. Using history, video-nystagmography 
                        and audiovestibular tests, we developed machine learning models to separate these two disorders. We recruited patients with VM or MD from a 
                        neurology outpatient facility. One hundred features from six “feature subsets”: history, acute video-nystagmography and four laboratory tests 
                        (video head impulse test, vestibular-evoked myogenic potentials, caloric testing and audiogram) were used. We applied ten machine learning 
                        algorithms to develop classification models. Modelling was performed using three “tiers” of data availability to simulate three clinical settings. 
                        “Tier 1” used all available data to simulate the neuro-otology clinic, “Tier 2” used only history, audiogram and caloric test data, representing 
                        the general neurology clinic, and “Tier 3” used history alone as occurs in primary care. Model performance was evaluated using tenfold 
                        cross-validation. Data from 160 patients with VM and 114 with MD were used for model development. All models effectively separated the two disorders 
                        for all three tiers, with accuracies of 85.77-97.81%. The best performing algorithms (AdaBoost and Random Forest) yielded accuracies of 97.81% 
                        (95% CI 95.24-99.60), 94.53% (91.09-99.52%) and 92.34% (92.28-96.76%) for tiers 1, 2 and 3. The best feature subset combination was history, acute 
                        video-nystagmography, video head impulse test and caloric testing, and the best single feature subset was history. Machine learning models can accurately 
                        differentiate between VM and MD and are promising tools to assist diagnosis by medical practitioners with diverse levels of expertise and resources. <br /> <br />
                      </div>
                      <div id="bibm14" class="popup-bib" style="display: none; font-size: 12px; text-align: left; white-space: pre; padding-top: -20px !important">
                        @article{wang2024machine,
                          title={Machine learning models help differentiate between causes of recurrent spontaneous vertigo},
                          author={Wang, Chao and Young, Allison S and Raj, Chahat and Bradshaw, Andrew P and Nham, Benjamin and Rosengren, Sally M and Calic, Zeljka and Burke, David and Halmagyi, G Michael and Bharathy, Gnana K and others},
                          journal={Journal of Neurology},
                          volume={271},
                          number={6},
                          pages={3426--3438},
                          year={2024},
                          publisher={Springer}
                        }
                      </div>                                            
                    </li>           
                    <!-- Publication 14 ends here -->

                    <!-- Publication 13 Starts Here -->
                    <li>
                      <p>
                        <a style="color: #000000">Analyzing Sentiments Towards E-Levy Policy Implementation in Ghana using Twitter Data.</a><br />
                        Peter Appiahene, Stephen Afrifa, Emmanuel Kyei Akwah, Arjun Choudhry, Inder Khatri, <a style="color: #f4a460">Chahat Raj</a> and Mukesh Prasad (International Journal of Information Technology 2024)
                        <button type="button" class="btn badge" style="background-color: #a7c7e7; color: #ffffff" data-popup="absm13">Abstract</button>
                        <a href="./files/m13.pdf"><button type="button" class="btn badge" style="background-color: #ec949c; color: #ffffff">PDF</button></a> <!-- TODO: add pdf -->
                        <a href=""><button type="button" class="btn badge" style="background-color: #ebce77; color: #ffffff">Code</button></a> <!-- TODO: add code -->
                        <button type="button" class="btn badge" style="background-color: #b8d8be; color: #ffffff" data-popup="bibm13">BibTeX</button>
                      </p>
                      <div id="absm13" class="popup-abs" style="display: none; font-size: 12px; text-align: justify;">
                        A newly proposed or implemented government policy often encounters challenges. Ghanaian citizens have always look down negatively upon their government's 
                        policies, hence those are rarely appreciated. This paper ponders over the Ghanaian government's proposal of electronic levy on mobile money transactions 
                        which was announced in the 2022 budget on November 17, 2021. We have scrutinized this governmental policy through the ordinary citizen's perspective using 
                        lexicon-based sentiment analysis on Twitter data. Lexicons are collections of words that express specific emotions, and deals with interpreting emotions like 
                        happiness, frustration, anger, and sadness. Twitter, serving as a means for people to share their views, provides enormous user generated content, beneficial 
                        for research purposes. We collected e-levy specific Twitter data in five phases, namely; policy introduction, popularity, discussion, feeble, and debate phases. 
                        The policy introduction phase recorded the least volume of data containing 1400 tweets, among which our sentiment analyzer classifies 8.93% as positive, 89.29% 
                        as neutral, and 1.78% as negative. The debate phase recorded the highest amount of data containing 18.423 tweets, among which 24.43% tweets are classified as 
                        positive, 59.29% as neutral, and 16.28% as negative. An analysis on the entire data containing 38,771 tweets reports 25.50% positive, 59.02% neutral, and 15.48% 
                        negative tweets. Our study determines that people are not largely unhappy established by the stable positive sentiment percentage, however, there is a high neutral 
                        score in all the phases. <br /> <br />
                      </div>
                      <div id="bibm13" class="popup-bib" style="display: none; font-size: 12px; text-align: left; white-space: pre; padding-top: -20px !important">
                        @article{appiahene2024analyzing,
                          title={Analyzing sentiments towards e-levy policy implementation in Ghana using twitter data},
                          author={Appiahene, Peter and Afrifa, Stephen and Akwah, Emmanuel Kyei and Choudhry, Arjun and Khatri, Inder and Raj, Chahat and Prasad, Mukesh},
                          journal={International Journal of Information Technology},
                          volume={16},
                          number={4},
                          pages={2199--2214},
                          year={2024},
                          publisher={Springer}
                        } <!-- TODO update bib -->
                      </div>                                            
                    </li>           
                    <!-- Publication 13 ends here -->

                  <!-- Publication 12 Starts Here -->
                  <li>
                    <p>
                      <a style="color: #000000">Understanding Social Media Engagement in Response to Disaster Fundraising Attempts During Australian Bushfires.</a><br />
                      Yohei Nii, <a style="color: #f4a460">Chahat Raj</a>, Muhammad Salman Tiwana, Mahendra Samarawickrama, Simeon Simoff, Tony Jan, and Mukesh Prasad (International Conference on Intelligent Vision and Computing 2022)
                      <button type="button" class="btn badge" style="background-color: #a7c7e7; color: #ffffff" data-popup="absm12">Abstract</button>
                      <a href="./files/m12.pdf"><button type="button" class="btn badge" style="background-color: #ec949c; color: #ffffff">PDF</button></a> <!-- TODO: add pdf -->
                      <a href=""><button type="button" class="btn badge" style="background-color: #ebce77; color: #ffffff">Code</button></a> <!-- TODO: add code -->
                      <button type="button" class="btn badge" style="background-color: #b8d8be; color: #ffffff" data-popup="bibm12">BibTeX</button>
                    </p>
                    <div id="absm12" class="popup-abs" style="display: none; font-size: 12px; text-align: justify;">
                      This article studies the impact of social media posts specific to a disaster incident - the Australian bushfires of 2019-2020. We analyse the social media 
                      content posted by the Australian Red Cross Organization's Facebook page, and the user generated comments on their posts. We identify user sentiments in response 
                      to the natural disaster and towards the organization's fundraising attempts. This study shall enable the stakeholders to understand how the general public reacts 
                      to fundraising protocols at the times of unforeseen disasters. It shall also allow policymakers to design sustainable goals to promote healthy donation behaviour 
                      through social media platforms. Further, we also analyse how benchmark Natural Language Processing tools, namely, VADER, Afinn, and TextBlob, perform in an 
                      unsupervised scenario to perform sentiment classification. Overall VADER results were best among the other algorithms Afinn and TextBlob in the term of accuracy, 
                      precision, recall and f1 score performance measure. <br /> <br />
                    </div>
                    <div id="bibm12" class="popup-bib" style="display: none; font-size: 12px; text-align: left; white-space: pre; padding-top: -20px !important">
                      @inproceedings{nii2022understanding,
                        title={Understanding Social Media Engagement in Response to Disaster Fundraising Attempts During Australian Bushfires},
                        author={Nii, Yohei and Raj, Chahat and Tiwana, Muhammad Salman and Samarawickrama, Mahendra and Simoff, Simeon and Jan, Tony and Prasad, Mukesh},
                        booktitle={International Conference on Intelligent Vision and Computing},
                        pages={277--289},
                        year={2022},
                        organization={Springer}
                      } <!-- TODO update bib -->
                    </div>                                            
                  </li>           
                  <!-- Publication 12 ends here -->

                  <!-- Publication 11 Starts Here -->
                  <li>
                    <p>
                      <a style="color: #000000">The Effectiveness of Social Media Engagement Strategy on Disaster Fundraising.</a><br />
                      Vivek Velivela, <a style="color: #f4a460">Chahat Raj</a>, Muhammad Salman Tiwana, Raj Prasanna, Mahendra Samarawickrama, and Mukesh Prasad (International Conference on Information Systems for Crisis Response and Management 2022)
                      <button type="button" class="btn badge" style="background-color: #a7c7e7; color: #ffffff" data-popup="absm11">Abstract</button>
                      <a href="./files/m11.pdf"><button type="button" class="btn badge" style="background-color: #ec949c; color: #ffffff">PDF</button></a> <!-- TODO: add pdf -->
                      <a href=""><button type="button" class="btn badge" style="background-color: #ebce77; color: #ffffff">Code</button></a> <!-- TODO: add code -->
                      <button type="button" class="btn badge" style="background-color: #b8d8be; color: #ffffff" data-popup="bibm11">BibTeX</button>
                    </p>
                    <div id="absm11" class="popup-abs" style="display: none; font-size: 12px; text-align: justify;">
                      Social media has been a powerful tool and integral part of communication, especially during natural disasters. Social media platforms help nonprofits in 
                      effective disaster management by disseminating crucial information to various communities at the earliest. Besides spreading information to every corner 
                      of the world, various platforms incorporate many features that give access to host online fundraising events, process online donations, etc. The current 
                      literature lacks the theoretical structure investigating the correlation between social media engagement and crisis management. Large nonprofit organisations 
                      like the Australian Red Cross have upscaled their operations to help nearly 6,000 bushfire survivors through various grants and helped 21,563 people with
                      psychological support and other assistance through their recovery program (Australian Red Cross, 2021). This paper considers the case of bushfires in Australia 
                      2019-2020 to inspect the role of social media in escalating fundraising via analysing the donation data of the Australian Red Cross from October 2019 - March 2020
                      and analysing the level of public interaction with their Facebook page and its content in the same period. <br /> <br />
                    </div>
                    <div id="bibm11" class="popup-bib" style="display: none; font-size: 12px; text-align: left; white-space: pre; padding-top: -20px !important">
                      @article{velivelaeffectiveness,
                        title={The Effectiveness of Social Media Engagement Strategy on Disaster Fundraising},
                        author={Velivela, Vivek and Raj, Chahat and Tiwana, Muhammad Salman and Prasanna, Raj and Samarawickrama, Mahendra and Prasad, Mukesh}
                      } <!-- TODO update bib -->
                    </div>                                            
                  </li>           
                  <!-- Publication 11 ends here -->

                  <!-- Publication 10 Starts Here -->
                  <li>
                    <p>
                      <a style="color: #000000">People Lie, Actions Don't! Modeling Infodemic Proliferation Predictors among Social Media Users.</a><br />
                      <a style="color: #f4a460">Chahat Raj</a>, and Priyanka Meel (Technology in Society 2022)
                      <button type="button" class="btn badge" style="background-color: #a7c7e7; color: #ffffff" data-popup="absm10">Abstract</button>
                      <a href="./files/m10.pdf"><button type="button" class="btn badge" style="background-color: #ec949c; color: #ffffff">PDF</button></a> <!-- TODO: add pdf -->
                      <a href=""><button type="button" class="btn badge" style="background-color: #ebce77; color: #ffffff">Code</button></a> <!-- TODO: add code -->
                      <button type="button" class="btn badge" style="background-color: #b8d8be; color: #ffffff" data-popup="bibm10">BibTeX</button>
                    </p>
                    <div id="absm10" class="popup-abs" style="display: none; font-size: 12px; text-align: justify;">
                      Social media is interactive, and interaction brings misinformation. With the growing amount of user-generated data, fake news on online platforms has become 
                      much more frequent since the arrival of social networks. Now and then, an event occurs and becomes the topic of discussion, generating and propagating false 
                      information. Existing literature studying fake news elaborates primarily on fake news classification models. Approaches exploring fake news characteristics 
                      to distinguish it from real news are minimal. Not much research has focused on statistical testing and generating new factor discoveries. This study assumes 
                      fifteen hypotheses to identify factors exhibiting a relationship with fake news. We perform the experiments on two real-world COVID-19 datasets using qualitative 
                      and quantitative testing methods. We determine the impact of conditional effects among sentiment, gender, and media usage. This study concludes that sentiment 
                      polarity and gender can significantly identify fake news. Dependence on the presence of visual media is, however, inconclusive. Additionally, Twitter-specific 
                      user engagement factors like followers count, friends count, favorite count, and retweet count significantly differ in fake and real news. Though, the contribution 
                      of status count is currently disputed. This study identifies practical factors to be conjunctly utilized in developing fake news detection algorithms. <br /> <br />
                    </div>
                    <div id="bibm10" class="popup-bib" style="display: none; font-size: 12px; text-align: left; white-space: pre; padding-top: -20px !important">
                      @article{raj2022people,
                        title={People lie, actions Don't! Modeling infodemic proliferation predictors among social media users},
                        author={Raj, Chahat and Meel, Priyanka},
                        journal={Technology in Society},
                        volume={68},
                        pages={101930},
                        year={2022},
                        publisher={Elsevier}
                      } <!-- TODO update bib -->
                    </div>                                            
                  </li>           
                  <!-- Publication 10 ends here -->

                  <!-- Publication 9 Starts Here -->
                  <li>
                    <p>
                      <a style="color: #000000">Is Dynamic Rumor Detection on Social Media Viable? An Unsupervised Perspective.</a><br />
                      <a style="color: #f4a460">Chahat Raj</a>, and Priyanka Meel (Arxiv Preprint 2021)
                      <button type="button" class="btn badge" style="background-color: #a7c7e7; color: #ffffff" data-popup="absm9">Abstract</button>
                      <a href="./files/m9.pdf"><button type="button" class="btn badge" style="background-color: #ec949c; color: #ffffff">PDF</button></a> <!-- TODO: add pdf -->
                      <a href="https://github.com/chahatraj/Unsupervised-Rumor-Detection"><button type="button" class="btn badge" style="background-color: #ebce77; color: #ffffff">Code</button></a> <!-- TODO: add code -->
                      <button type="button" class="btn badge" style="background-color: #b8d8be; color: #ffffff" data-popup="bibm9">BibTeX</button>
                    </p>
                    <div id="absm9" class="popup-abs" style="display: none; font-size: 12px; text-align: justify;">
                      With the growing popularity and ease of access to the internet, the problem of online rumors is escalating. People are relying on social media to gain information 
                      readily but fall prey to false information. There is a lack of credibility assessment techniques for online posts to identify rumors as soon as they arrive. 
                      Existing studies have formulated several mechanisms to combat online rumors by developing machine learning and deep learning algorithms. The literature so far 
                      provides supervised frameworks for rumor classification that rely on huge training datasets. However, in the online scenario where supervised learning is exigent,
                      dynamic rumor identification becomes difficult. Early detection of online rumors is a challenging task, and studies relating to them are relatively few. It is the need 
                      of the hour to identify rumors as soon as they appear online. This work proposes a novel framework for unsupervised rumor detection that relies on an online post's 
                      content and social features using state-of-the-art clustering techniques. The proposed architecture outperforms several existing baselines and performs better than 
                      several supervised techniques. The proposed method, being lightweight, simple, and robust, offers the suitability of being adopted as a tool for online rumor identification. <br /> <br />
                    </div>
                    <div id="bibm9" class="popup-bib" style="display: none; font-size: 12px; text-align: left; white-space: pre; padding-top: -20px !important">
                      @article{raj2021dynamic,
                        title={Is dynamic rumor detection on social media viable? an unsupervised perspective},
                        author={Raj, Chahat and Meel, Priyanka},
                        journal={arXiv preprint arXiv:2111.11982},
                        year={2021}
                      } <!-- TODO update bib -->
                    </div>                                            
                  </li>           
                  <!-- Publication 9 ends here -->

                  <!-- Publication 8 Starts Here -->
                  <li>
                    <p>
                      <a style="color: #000000">A Review of Web Infodemic Analysis and Detection Trends across Multi-modalities using Deep Neural Networks.</a><br />
                      <a style="color: #f4a460">Chahat Raj</a>, and Priyanka Meel (Arxiv Preprint 2021)
                      <button type="button" class="btn badge" style="background-color: #a7c7e7; color: #ffffff" data-popup="absm8">Abstract</button>
                      <a href="./files/m8.pdf"><button type="button" class="btn badge" style="background-color: #ec949c; color: #ffffff">PDF</button></a> <!-- TODO: add pdf -->
                      <a href=""><button type="button" class="btn badge" style="background-color: #ebce77; color: #ffffff">Code</button></a> <!-- TODO: add code -->
                      <button type="button" class="btn badge" style="background-color: #b8d8be; color: #ffffff" data-popup="bibm8">BibTeX</button>
                    </p>
                    <div id="absm8" class="popup-abs" style="display: none; font-size: 12px; text-align: justify;">
                      Fake news and misinformation is a matter of concern for people around the globe. Users of the internet and social media sites encounter content with false 
                      information much frequently. Fake news detection is one of the most analyzed and prominent areas of research. These detection techniques apply popular machine 
                      learning and deep learning algorithms. Previous work in this domain covers fake news detection vastly among text circulating online. Platforms that have extensively 
                      been observed and analyzed include news websites and Twitter. Facebook, Reddit, WhatsApp, YouTube, and other social applications are gradually gaining attention in 
                      this emerging field. Researchers are analyzing online data based on multiple modalities composed of text, image, video, speech, and other contributing factors. The 
                      combination of various modalities has resulted in efficient fake news detection. At present, there is an abundance of surveys consolidating textual fake news detection 
                      algorithms. This review primarily deals with multi-modal fake news detection techniques that include images, videos, and their combinations with text. We provide a
                      comprehensive literature survey of eighty articles presenting state-of-the-art detection techniques, thereby identifying research gaps and building a pathway for 
                      researchers to further advance this domain. <br /> <br />
                    </div>
                    <div id="bibm8" class="popup-bib" style="display: none; font-size: 12px; text-align: left; white-space: pre; padding-top: -20px !important">
                      @article{raj2021review,
                        title={A Review of Web Infodemic Analysis and Detection Trends across Multi-modalities using Deep Neural Networks},
                        author={Raj, Chahat and Meel, Priyanka},
                        journal={arXiv preprint arXiv:2112.00803},
                        year={2021}
                      } <!-- TODO update bib -->
                    </div>                                            
                  </li>           
                  <!-- Publication 8 ends here -->

                  <!-- Publication 7 Starts Here -->
                  <li>
                    <p>
                      <a style="color: #000000">Cyberbullying Detection: Hybrid Models based on Machine Learning and Natural Language Processing Techniques.</a><br />
                      <a style="color: #f4a460">Chahat Raj</a>, Ayush Agarwal, Gnana Bharathy, Bhuva Narayan, and Mukesh Prasad (Electronics 2021)
                      <button type="button" class="btn badge" style="background-color: #a7c7e7; color: #ffffff" data-popup="absm7">Abstract</button>
                      <a href="./files/m7.pdf"><button type="button" class="btn badge" style="background-color: #ec949c; color: #ffffff">PDF</button></a> <!-- TODO: add pdf -->
                      <a href=""><button type="button" class="btn badge" style="background-color: #ebce77; color: #ffffff">Code</button></a> <!-- TODO: add code -->
                      <button type="button" class="btn badge" style="background-color: #b8d8be; color: #ffffff" data-popup="bibm7">BibTeX</button>
                    </p>
                    <div id="absm7" class="popup-abs" style="display: none; font-size: 12px; text-align: justify;">
                      The rise in web and social media interactions has resulted in the efortless proliferation of offensive language and hate speech. Such online harassment, insults, 
                      and attacks are commonly termed cyberbullying. The sheer volume of user-generated content has made it challenging to identify such illicit content. Machine learning 
                      has wide applications in text classification, and researchers are shifting towards using deep neural networks in detecting cyberbullying due to the several 
                      advantages they have over traditional machine learning algorithms. This paper proposes a novel neural network framework with parameter optimization and an algorithmic 
                      comparative study of eleven classification methods: four traditional machine learning and seven shallow neural networks on two real world cyberbullying datasets. In 
                      addition, this paper also examines the effect of feature extraction and word-embedding-techniques-based natural language processing on algorithmic performance. Key 
                      observations from this study show that bidirectional neural networks and attention models provide high classification results. Logistic Regression was observed to be 
                      the best among the traditional machine learning classifiers used. Term Frequency-Inverse Document Frequency (TF-IDF) demonstrates consistently high accuracies with 
                      traditional machine learning techniques. Global Vectors (GloVe) perform better with neural network models. Bi-GRU and Bi-LSTM worked best amongst the neural networks 
                      used. The extensive experiments performed on the two datasets establish the importance of this work by comparing eleven classification methods and seven feature 
                      extraction techniques. Our proposed shallow neural networks outperform existing state-of-the-art approaches for cyberbullying detection, with accuracy and F1-scores 
                      as high as ~95% and ~98%, respectively. <br /> <br />
                    </div>
                    <div id="bibm7" class="popup-bib" style="display: none; font-size: 12px; text-align: left; white-space: pre; padding-top: -20px !important">
                      @article{raj2021cyberbullying,
                        title={Cyberbullying detection: Hybrid models based on machine learning and natural language processing techniques},
                        author={Raj, Chahat and Agarwal, Ayush and Bharathy, Gnana and Narayan, Bhuva and Prasad, Mukesh},
                        journal={Electronics},
                        volume={10},
                        number={22},
                        pages={2810},
                        year={2021},
                        publisher={MDPI}
                      } <!-- TODO update bib -->
                    </div>                                            
                  </li>           
                  <!-- Publication 7 ends here -->

                  <!-- Publication 6 Starts Here -->
                  <li>
                    <p>
                      <a style="color: #000000">Machine Learning Techniques for Differential Diagnosis of Vertigo and Dizziness: A Review.</a><br />
                      Varad Kabade, Ritika Hooda, <a style="color: #f4a460">Chahat Raj</a>, Zainab Awan, Allison S Young, Miriam S Welgampola, and Mukesh Prasad (Sensors 2021)
                      <button type="button" class="btn badge" style="background-color: #a7c7e7; color: #ffffff" data-popup="absm6">Abstract</button>
                      <a href="./files/m6.pdf"><button type="button" class="btn badge" style="background-color: #ec949c; color: #ffffff">PDF</button></a> <!-- TODO: add pdf -->
                      <a href=""><button type="button" class="btn badge" style="background-color: #ebce77; color: #ffffff">Code</button></a> <!-- TODO: add code -->
                      <button type="button" class="btn badge" style="background-color: #b8d8be; color: #ffffff" data-popup="bibm6">BibTeX</button>
                    </p>
                    <div id="absm6" class="popup-abs" style="display: none; font-size: 12px; text-align: justify;">
                      Vertigo is a sensation of movement that results from disorders of the inner ear balance organs and their central connections, with aetiologies that are often 
                      benign and sometimes serious. An individual who develops vertigo can be effectively treated only after a correct diagnosis of the underlying vestibular disorder 
                      is reached. Recent advances in artificial intelligence promise novel strategies for the diagnosis and treatment of patients with this common symptom. Human 
                      analysts may experience difficulties manually extracting patterns from large clinical datasets. Machine learning techniques can be used to visualize, understand, 
                      and classify clinical data to create a computerized, faster, and more accurate evaluation of vertiginous disorders. Practitioners can also use them as a teaching 
                      tool to gain knowledge and valuable insights from medical data. This paper provides a review of the literatures from 1999 to 2021 using various feature extraction 
                      and machine learning techniques to diagnose vertigo disorders. This paper aims to provide a better understanding of the work done thus far and to provide future 
                      directions for research into the use of machine learning in vertigo diagnosis. <br /> <br />
                    </div>
                    <div id="bibm6" class="popup-bib" style="display: none; font-size: 12px; text-align: left; white-space: pre; padding-top: -20px !important">
                      @article{kabade2021machine,
                        title={Machine learning techniques for differential diagnosis of vertigo and dizziness: a review},
                        author={Kabade, Varad and Hooda, Ritika and Raj, Chahat and Awan, Zainab and Young, Allison S and Welgampola, Miriam S and Prasad, Mukesh},
                        journal={Sensors},
                        volume={21},
                        number={22},
                        pages={7565},
                        year={2021},
                        publisher={MDPI}
                      } <!-- TODO update bib -->
                    </div>                                            
                  </li>           
                  <!-- Publication 6 ends here -->

                  <!-- Publication 5 Starts Here -->
                  <li>
                    <p>
                      <a style="color: #000000">ARCNN Framework for Multimodal Infodemic Detection.</a><br />
                      <a style="color: #f4a460">Chahat Raj</a>, and Priyanka Meel (Neural Networks 2021)
                      <button type="button" class="btn badge" style="background-color: #a7c7e7; color: #ffffff" data-popup="absm5">Abstract</button>
                      <a href="./files/m5.pdf"><button type="button" class="btn badge" style="background-color: #ec949c; color: #ffffff">PDF</button></a> <!-- TODO: add pdf -->
                      <a href="https://github.com/chahatraj/TIPNet-Infodemic-Detection"><button type="button" class="btn badge" style="background-color: #ebce77; color: #ffffff">Code</button></a> <!-- TODO: add code -->
                      <button type="button" class="btn badge" style="background-color: #b8d8be; color: #ffffff" data-popup="bibm5">BibTeX</button>
                    </p>
                    <div id="absm5" class="popup-abs" style="display: none; font-size: 12px; text-align: justify;">
                      Fake news and misinformation have adopted various propagation media over time, nowadays spreading predominantly through online social networks. During the 
                      ongoing COVID-19 pandemic, false information is affecting human life in many spheres The world needs automated detection technology and efforts are being 
                      made to meet this requirement with the use of artificial intelligence. Neural network detection mechanisms are robust and durable and hence are used extensively 
                      in fake news detection. Deep learning algorithms demonstrate efficiency when they are provided with a large amount of training data. Given the scarcity of 
                      relevant fake news datasets, we built the Coronavirus Infodemic Dataset (CovID), which contains fake news posts and articles related to coronavirus. This paper 
                      presents a novel framework, the Allied Recurrent and Convolutional Neural Network (ARCNN), to detect fake news based on two different modalities: text and image. 
                      Our approach uses recurrent neural networks (RNNs) and convolutional neural networks (CNNs) and combines both streams to generate a final prediction. We present 
                      extensive research on various popular RNN and CNN models and their performance on six coronavirus-specific fake news datasets. To exhaustively analyze performance, 
                      we present experimentation performed and results obtained by combining both modalities using early fusion and four types of late fusion techniques. The proposed 
                      framework is validated by comparisons with state-of-the-art fake news detection mechanisms, and our models outperform each of them. <br /> <br />
                    </div>
                    <div id="bibm5" class="popup-bib" style="display: none; font-size: 12px; text-align: left; white-space: pre; padding-top: -20px !important">
                      @article{raj2022arcnn,
                        title={ARCNN framework for multimodal infodemic detection},
                        author={Raj, Chahat and Meel, Priyanka},
                        journal={Neural Networks},
                        volume={146},
                        pages={36--68},
                        year={2022},
                        publisher={Elsevier}
                      } <!-- TODO update bib -->
                    </div>                                            
                  </li>           
                  <!-- Publication 5 ends here -->

                  <!-- Publication 4 Starts Here -->
                  <li>
                    <p>
                      <a style="color: #000000">ConvNet Frameworks for Multi-Modal Fake News Detection.</a><br />
                      <a style="color: #f4a460">Chahat Raj</a>, and Priyanka Meel (Applied Intelligence 2021)
                      <button type="button" class="btn badge" style="background-color: #a7c7e7; color: #ffffff" data-popup="absm4">Abstract</button>
                      <a href="./files/m4.pdf"><button type="button" class="btn badge" style="background-color: #ec949c; color: #ffffff">PDF</button></a> <!-- TODO: add pdf -->
                      <a href="https://github.com/chahatraj/ConvNets-for-Multimodal-Fake-News-Detection"><button type="button" class="btn badge" style="background-color: #ebce77; color: #ffffff">Code</button></a> <!-- TODO: add code -->
                      <button type="button" class="btn badge" style="background-color: #b8d8be; color: #ffffff" data-popup="bibm4">BibTeX</button>
                    </p>
                    <div id="absm4" class="popup-abs" style="display: none; font-size: 12px; text-align: justify;">
                      An upsurge of false information revolves around the internet. Social media and websites are flooded with unverified news posts. These posts are comprised of text, 
                      images, audio, and videos. There is a requirement for a system that detects fake content in multiple data modalities. We have seen a considerable amount of research 
                      on classification techniques for textual fake news detection, while frameworks dedicated to visual fake news detection are very few. We explored the state-of-the-art 
                      methods using deep networks such as CNNs and RNNs for multi-modal online information credibility analysis. They show rapid improvement in classification tasks without 
                      requiring pre-processing. To aid the ongoing research over fake news detection using CNN models, we build textual and visual modules to analyze their performances over 
                      multi-modal datasets. We exploit latent features present inside text and images using layers of convolutions. We see how well these convolutional neural networks 
                      perform classification when provided with only latent features and analyze what type of images are needed to be fed to perform efficient fake news detection. We propose 
                      a multi-modal Coupled ConvNet architecture that fuses both the data modules and efficiently classifies online news depending on its textual and visual content. We thence 
                      offer a comparative analysis of the results of all the models utilized over three datasets. The proposed architecture outperforms various state-of-the-art methods for 
                      fake news detection with considerably high accuracies. <br /> <br />
                    </div>
                    <div id="bibm4" class="popup-bib" style="display: none; font-size: 12px; text-align: left; white-space: pre; padding-top: -20px !important">
                      @article{raj2021convnet,
                        title={ConvNet frameworks for multi-modal fake news detection},
                        author={Raj, Chahat and Meel, Priyanka},
                        journal={Applied Intelligence},
                        volume={51},
                        number={11},
                        pages={8132--8148},
                        year={2021},
                        publisher={Springer}
                      } <!-- TODO update bib -->
                    </div>                                            
                  </li>           
                  <!-- Publication 4 ends here -->

                  <!-- Publication 3 Starts Here -->
                  <li>
                    <p>
                      <a style="color: #000000">Microblogs Deception Detection using BERT and Multiscale CNNs.</a><br />
                      <a style="color: #f4a460">Chahat Raj</a>, and Priyanka Meel (Global Conference for Advancement in Technology 2021)
                      <button type="button" class="btn badge" style="background-color: #a7c7e7; color: #ffffff" data-popup="absm3">Abstract</button>
                      <a href="./files/m3.pdf"><button type="button" class="btn badge" style="background-color: #ec949c; color: #ffffff">PDF</button></a> <!-- TODO: add pdf -->
                      <a href="https://github.com/chahatraj/Multiscale-CNNs"><button type="button" class="btn badge" style="background-color: #ebce77; color: #ffffff">Code</button></a> <!-- TODO: add code -->
                      <button type="button" class="btn badge" style="background-color: #b8d8be; color: #ffffff" data-popup="bibm3">BibTeX</button>
                    </p>
                    <div id="absm3" class="popup-abs" style="display: none; font-size: 12px; text-align: justify;">
                      Online news consumption has rapidly increased, and so has the proliferation of false information. People worldwide have mainly become dependent on social media
                      networks to intake news about the happenings around them. Also, the data is profoundly contaminated with wrong information that harms society in uncountable ways. 
                      It is of huge importance to be able to identify a false message. The research society is contributing to solving the problem by developing machine learning and 
                      deep learning algorithms. With misinformation spreading ubiquitously, various data modalities have emerged that become carriers of such false news. Research trend 
                      is advancing towards multi-modal fake news detection to authenticate text, images, and videos on the web. Existing studies have elaborated on the successful use of
                      RNNs and CNNs. Being a new NLP technique, BERT has been used by a limited number of studies, while multiscale CNNs have not been explored yet to apply fake news 
                      detection. This research proposes a novel framework using BERT and multiscale CNNs to perform multi-modal fake news classification and achieve results higher than 
                      the existing stateof-the-art techniques. <br /> <br />
                    </div>
                    <div id="bibm3" class="popup-bib" style="display: none; font-size: 12px; text-align: left; white-space: pre; padding-top: -20px !important">
                      @inproceedings{raj2021microblogs,
                        title={Microblogs Deception Detection using BERT and Multiscale CNNs},
                        author={Raj, Chahat and Meel, Priyanka},
                        booktitle={2021 2nd Global Conference for Advancement in Technology (GCAT)},
                        pages={1--6},
                        year={2021},
                        organization={IEEE}
                      } <!-- TODO update bib -->
                    </div>                                            
                  </li>           
                  <!-- Publication 3 ends here -->

                  <!-- Publication 2 Starts Here -->
                  <li>
                    <p>
                      <a style="color: #000000">MediaEval 2020: An Ensemble-based Multimodal Approach for Coronavirus and 5G Conspiracy Tweet Detection.</a><br />
                      <a style="color: #f4a460">Chahat Raj</a>, and Mihir P Mehta (MediaEval 2020)
                      <button type="button" class="btn badge" style="background-color: #a7c7e7; color: #ffffff" data-popup="absm2">Abstract</button>
                      <a href="./files/m2.pdf"><button type="button" class="btn badge" style="background-color: #ec949c; color: #ffffff">PDF</button></a> <!-- TODO: add pdf -->
                      <a href=""><button type="button" class="btn badge" style="background-color: #ebce77; color: #ffffff">Code</button></a> <!-- TODO: add code -->
                      <button type="button" class="btn badge" style="background-color: #b8d8be; color: #ffffff" data-popup="bibm2">BibTeX</button>
                    </p>
                    <div id="absm2" class="popup-abs" style="display: none; font-size: 12px; text-align: justify;">
                      In the wake of ongoing COVID-19 pandemic, a parallel stream of misinformation and conspiracies rises on the internet. People around the world are being flooded 
                      with texts and visuals claiming false statements linked with coronavirus disease. This paper presents a multi-modal fake news detection system that uses text and 
                      image features to detect conspiracy tweets. This research has been performed in context with the FakeNews: Coronavirus and 5G Conspiracy task of MediaEval 2020. 
                      The NLP subtask we have performed utilizes an ensemble of machine learning and deep learning algorithms for the analysis of textualvisual data. We demonstrate the 
                      performances of experiments performed for each modality and results obtained after their fusion. <br /> <br />
                    </div>
                    <div id="bibm2" class="popup-bib" style="display: none; font-size: 12px; text-align: left; white-space: pre; padding-top: -20px !important">
                      @inproceedings{raj2020mediaeval,
                        title={MediaEval 2020: An Ensemble-based Multimodal Approach for Coronavirus and 5G Conspiracy Tweet Detection.},
                        author={Raj, Chahat and Mehta, Mihir},
                        booktitle={MediaEval},
                        year={2020}
                      } <!-- TODO update bib -->
                    </div>                                            
                  </li>           
                  <!-- Publication 2 ends here -->

                  <!-- Publication 1 Starts Here -->
                  <li>
                    <p>
                      <a style="color: #000000">Fake News on Multiple Online Social Networks.</a><br />
                      <a style="color: #f4a460">Chahat Raj</a>, and Priyanka Meel (ICPCCAI 2020)
                      <button type="button" class="btn badge" style="background-color: #a7c7e7; color: #ffffff" data-popup="absm1">Abstract</button>
                      <a href="./files/m1.pdf"><button type="button" class="btn badge" style="background-color: #ec949c; color: #ffffff">PDF</button></a> <!-- TODO: add pdf -->
                      <a href=""><button type="button" class="btn badge" style="background-color: #ebce77; color: #ffffff">Code</button></a> <!-- TODO: add code -->
                      <button type="button" class="btn badge" style="background-color: #b8d8be; color: #ffffff" data-popup="bibm1">BibTeX</button>
                    </p>
                    <div id="absm1" class="popup-abs" style="display: none; font-size: 12px; text-align: justify;">
                      In the present decade, social media is taking over as a large ubiquitous platform to access and disseminate news. While some are official news sources, a
                      majority of accounts on Online Social Networks are indulged into sharing fake news. Social media comprises of a large set of information which users can readily 
                      access to. The reliability of posts that user access, absorb and share is not well specified. In this paper, we review the transmission of fake news on multiple 
                      Online Social Networks (OSNs). We consider three most used social networks in the current era: Twitter, Facebook and Instagram. We study i) fake news taxonomy, 
                      actors and impacts, ii) how fake news radiates on social media, iii) nature of fake news on multiple platforms, iv) how multiple networks can be inter-related to 
                      check fake news and v) how propagation and detection works on each OSN individually. We have presented fake news statistics, taxonomies, exposure on social media, 
                      current trends on prevention and detection of fake news on multiple social media platforms. We have also discussed ways to limit the radiation of fake news.  <br /> <br />
                    </div>
                    <div id="bibm1" class="popup-bib" style="display: none; font-size: 12px; text-align: left; white-space: pre; padding-top: -20px !important">
                      @article{rajfake,
                        title={Fake News on Multiple Online Social Networks},
                        author={Raj, Chahat and Meel, Priyanka}
                      } <!-- TODO update bib -->
                    </div>                                            
                  </li>           
                  <!-- Publication 1 ends here -->

                      <br />
                      <script src="js/jquery.min.js"></script>
                      <script src="js/jquery-migrate-3.0.1.min.js"></script>
                      <script src="js/popper.min.js"></script>
                      <script src="js/bootstrap.min.js"></script>
                      <script src="js/jquery.easing.1.3.js"></script>
                      <script src="js/jquery.waypoints.min.js"></script>
                      <script src="js/jquery.stellar.min.js"></script>
                      <script src="js/owl.carousel.min.js"></script>
                      <script src="js/jquery.magnific-popup.min.js"></script>
                      <script src="js/aos.js"></script>
                      <script src="js/jquery.animateNumber.min.js"></script>
                      <script src="js/bootstrap-datepicker.js"></script>
                      <script src="js/jquery.timepicker.min.js"></script>
                      <script src="js/scrollax.min.js"></script>
                      <script src="https://maps.googleapis.com/maps/api/js?key=AIzaSyBVWaKrjvy3MaE7SQ74_uJiULgl1JY0H2s&sensor=false"></script>
                      <script src="js/google-map.js"></script>
                      <script src="js/main.js"></script>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </section>
        </div>
      </div>
    </div>
    <script>
      document.addEventListener('DOMContentLoaded', function() {
        var badges = document.querySelectorAll("[data-popup]");
        badges.forEach(function(badge) {
          var popup = document.getElementById(badge.dataset.popup);
          badge.addEventListener("click", function() {
            if (popup.style.display === "none") {
              popup.style.display = "block"; // Show the popup
            } else {
              popup.style.display = "none"; // Hide the popup
            }
          });
        });
      });
    </script> 
  </body>
</html>
